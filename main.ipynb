{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Output CNN for Speech Recognition and Gender Classification\n",
        "\n",
        "This notebook implements a **Multi-Output CNN** that predicts both digit and gender simultaneously:\n",
        "\n",
        "## üß† Methodology\n",
        "1. **Feature Extraction**\n",
        "   - Extract Mel-Frequency Cepstral Coefficients (MFCCs) from audio recordings using Librosa\n",
        "   - Standardize input shape by padding/truncating sequences to a fixed length\n",
        "\n",
        "2. **Data Preparation**\n",
        "   - Convert audio into numpy arrays of shape (n_mfcc, time, 1)\n",
        "   - Encode labels:\n",
        "     - Gender ‚Üí one-hot vector ([1,0] = male, [0,1] = female)\n",
        "     - Digit ‚Üí one-hot vector of length 10\n",
        "\n",
        "3. **Model Architecture (Multi-Output CNN)**\n",
        "   - Convolutional Neural Network (CNN) extracts time‚Äìfrequency patterns\n",
        "   - Shared convolutional layers ‚Üí two output branches:\n",
        "     - Gender classifier (softmax over 2 classes)\n",
        "     - Digit classifier (softmax over 10 classes)\n",
        "\n",
        "4. **Training & Evaluation**\n",
        "   - Train/test split = 70/30\n",
        "   - Loss function = categorical crossentropy (for both tasks)\n",
        "   - Metrics = accuracy, precision, recall, F1-score\n",
        "   - Visualization of training history (accuracy/loss curves)\n",
        "\n",
        "## Dataset Structure\n",
        "```\n",
        "Dataset/\n",
        "   d0/ (digit 0)\n",
        "      male/   ‚Üí male speakers saying \"zero\"\n",
        "      female/ ‚Üí female speakers saying \"zero\"\n",
        "   d1/ (digit 1)\n",
        "      male/   ‚Üí male speakers saying \"one\"\n",
        "      female/ ‚Üí female speakers saying \"one\"\n",
        "   ...\n",
        "   d9/ (digit 9)\n",
        "      male/   ‚Üí male speakers saying \"nine\"\n",
        "      female/ ‚Üí female speakers saying \"nine\"\n",
        "```\n",
        "\n",
        "**Note**: We predict BOTH digit (0-9) AND gender (male/female) simultaneously using a Multi-Output CNN.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add src directory to path\n",
        "sys.path.append('src')\n",
        "\n",
        "# Import our Multi-Output CNN modules\n",
        "from extract_features import create_cnn_dataset\n",
        "from train_model import train_multi_output_cnn_pipeline\n",
        "from evaluate_model import evaluate_multi_output_cnn_pipeline\n",
        "\n",
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(\"üéØ Ready to implement gender classification for speech recognition\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Analysis and Multi-Output Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset configuration\n",
        "DATASET_PATH = \"Dataset\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=== MULTI-OUTPUT DATASET ANALYSIS ===\")\n",
        "print(\"üìÅ Analyzing dataset structure for Multi-Output CNN (Digit + Gender classification)...\")\n",
        "\n",
        "# Count files by digit and gender\n",
        "digit_counts = {}\n",
        "gender_counts = {'male': 0, 'female': 0}\n",
        "total_files = 0\n",
        "\n",
        "for digit in range(10):\n",
        "    digit_dir = os.path.join(DATASET_PATH, f'd{digit}')\n",
        "    if os.path.exists(digit_dir):\n",
        "        digit_count = 0\n",
        "        \n",
        "        # Count male files\n",
        "        male_dir = os.path.join(digit_dir, 'male')\n",
        "        if os.path.exists(male_dir):\n",
        "            male_files = len([f for f in os.listdir(male_dir) if f.endswith('.wav')])\n",
        "            gender_counts['male'] += male_files\n",
        "            digit_count += male_files\n",
        "\n",
        "        # Count female files\n",
        "        female_dir = os.path.join(digit_dir, 'female')\n",
        "        if os.path.exists(female_dir):\n",
        "            female_files = len([f for f in os.listdir(female_dir) if f.endswith('.wav')])\n",
        "            gender_counts['female'] += female_files\n",
        "            digit_count += female_files\n",
        "        \n",
        "        digit_counts[f'Digit {digit}'] = digit_count\n",
        "        total_files += digit_count\n",
        "\n",
        "print(f\"üìä Multi-Output Dataset Statistics:\")\n",
        "print(f\"   Total audio files: {total_files}\")\n",
        "print(f\"   Male samples: {gender_counts['male']}\")\n",
        "print(f\"   Female samples: {gender_counts['female']}\")\n",
        "print(f\"   Gender distribution: {gender_counts['male']/total_files*100:.1f}% Male, {gender_counts['female']/total_files*100:.1f}% Female\")\n",
        "\n",
        "print(f\"\\nüìä Digit Distribution:\")\n",
        "for digit, count in digit_counts.items():\n",
        "    print(f\"   {digit}: {count} files\")\n",
        "\n",
        "# Visualize distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Gender distribution\n",
        "axes[0].pie([gender_counts['male'], gender_counts['female']], \n",
        "           labels=['Male', 'Female'], autopct='%1.1f%%', \n",
        "           colors=['lightblue', 'lightpink'], startangle=90)\n",
        "axes[0].set_title('Gender Distribution')\n",
        "\n",
        "# Digit distribution\n",
        "digits = list(digit_counts.keys())\n",
        "counts = list(digit_counts.values())\n",
        "bars = axes[1].bar(digits, counts, alpha=0.7, color='lightgreen')\n",
        "axes[1].set_title('Digit Distribution')\n",
        "axes[1].set_ylabel('Number of Samples')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "for bar, count in zip(bars, counts):\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
        "                 str(count), ha='center', va='bottom')\n",
        "\n",
        "# Combined distribution\n",
        "axes[2].text(0.5, 0.7, f'Total Files: {total_files}', ha='center', va='center', \n",
        "             fontsize=16, fontweight='bold', transform=axes[2].transAxes)\n",
        "axes[2].text(0.5, 0.5, f'Male: {gender_counts[\"male\"]}', ha='center', va='center', \n",
        "             fontsize=14, transform=axes[2].transAxes)\n",
        "axes[2].text(0.5, 0.3, f'Female: {gender_counts[\"female\"]}', ha='center', va='center', \n",
        "             fontsize=14, transform=axes[2].transAxes)\n",
        "axes[2].set_title('Summary')\n",
        "axes[2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Multi-output dataset analysis completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Multi-Output CNN Pipeline: Feature Extraction, Training & Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== MFCC FEATURE EXTRACTION ===\")\n",
        "print(\"üéµ Performing MFCC feature extraction from audio files...\")\n",
        "\n",
        "# Initialize gender classifier\n",
        "classifier = GenderClassifier(sr=22050, n_mfcc=13)\n",
        "\n",
        "# Load and process a sample audio file to demonstrate MFCC extraction\n",
        "sample_file = None\n",
        "for digit in range(10):\n",
        "    digit_dir = os.path.join(DATASET_PATH, f'd{digit}')\n",
        "    if os.path.exists(digit_dir):\n",
        "        male_dir = os.path.join(digit_dir, 'male')\n",
        "        if os.path.exists(male_dir):\n",
        "            wav_files = [f for f in os.listdir(male_dir) if f.endswith('.wav')]\n",
        "            if wav_files:\n",
        "                sample_file = os.path.join(male_dir, wav_files[0])\n",
        "                break\n",
        "\n",
        "if sample_file:\n",
        "    print(f\"üìÅ Sample file: {sample_file}\")\n",
        "    \n",
        "    # Extract MFCC features from sample\n",
        "    sample_features = classifier.extract_mfcc_features(sample_file)\n",
        "    \n",
        "    print(f\"üéØ MFCC Features extracted:\")\n",
        "    print(f\"   Feature vector dimension: {len(sample_features)}\")\n",
        "    print(f\"   MFCC coefficients: {classifier.n_mfcc}\")\n",
        "    print(f\"   Statistical features per coefficient: 6 (mean, std, min, max, skew, kurtosis)\")\n",
        "    print(f\"   Additional audio features: 6 (spectral centroid, rolloff, zero-crossing)\")\n",
        "    \n",
        "    # Visualize MFCC features\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    \n",
        "    # Load audio for visualization\n",
        "    import librosa\n",
        "    y, sr = librosa.load(sample_file, sr=22050)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    \n",
        "    # Plot MFCC\n",
        "    plt.subplot(2, 2, 1)\n",
        "    librosa.display.specshow(mfcc, sr=sr, x_axis='time')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('MFCC Features')\n",
        "    plt.ylabel('MFCC Coefficients')\n",
        "    \n",
        "    # Plot audio waveform\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(y)\n",
        "    plt.title('Audio Waveform')\n",
        "    plt.xlabel('Sample')\n",
        "    plt.ylabel('Amplitude')\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.subplot(2, 2, 3)\n",
        "    feature_names = [f'MFCC{i//6}_{[\"mean\", \"std\", \"min\", \"max\", \"skew\", \"kurtosis\"][i%6]}' \n",
        "                    for i in range(classifier.n_mfcc * 6)] + \\\n",
        "                   ['spec_centroid_mean', 'spec_centroid_std', 'spec_rolloff_mean', \n",
        "                    'spec_rolloff_std', 'zcr_mean', 'zcr_std']\n",
        "    \n",
        "    # Show first 20 features\n",
        "    plt.bar(range(20), sample_features[:20])\n",
        "    plt.title('First 20 Extracted Features')\n",
        "    plt.xlabel('Feature Index')\n",
        "    plt.ylabel('Feature Value')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Plot feature distribution\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.hist(sample_features, bins=30, alpha=0.7, edgecolor='black')\n",
        "    plt.title('Feature Value Distribution')\n",
        "    plt.xlabel('Feature Value')\n",
        "    plt.ylabel('Frequency')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ MFCC feature extraction demonstrated successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå No sample audio file found for demonstration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the complete Multi-Output CNN pipeline\n",
        "print(\"üöÄ Starting Multi-Output CNN Pipeline...\")\n",
        "\n",
        "# Step 1: Create CNN dataset with MFCC features\n",
        "print(\"\\nüìä Step 1: Creating CNN dataset with MFCC features...\")\n",
        "mfcc_features, digit_labels, gender_labels = create_cnn_dataset(\n",
        "    dataset_path=DATASET_PATH,\n",
        "    output_dir=os.path.join(OUTPUT_DIR, 'cnn_data'),\n",
        "    sample_size=100  # Use small sample for demo\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Dataset created:\")\n",
        "print(f\"   - MFCC features shape: {mfcc_features.shape}\")\n",
        "print(f\"   - Digit labels shape: {digit_labels.shape}\")\n",
        "print(f\"   - Gender labels shape: {gender_labels.shape}\")\n",
        "\n",
        "# Step 2: Train Multi-Output CNN\n",
        "print(\"\\nüß† Step 2: Training Multi-Output CNN...\")\n",
        "trainer = train_multi_output_cnn_pipeline(\n",
        "    dataset_path=DATASET_PATH,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    sample_size=100,  # Use small sample for demo\n",
        "    epochs=50,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Step 3: Load test data for evaluation\n",
        "print(\"\\nüìà Step 3: Loading test data for evaluation...\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Apply 70/30 split (same as training)\n",
        "X_train, X_test, y_gender_train, y_gender_test, y_digit_train, y_digit_test = train_test_split(\n",
        "    mfcc_features, gender_labels, digit_labels,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=np.argmax(gender_labels, axis=1)\n",
        ")\n",
        "\n",
        "# Step 4: Evaluate the trained model\n",
        "print(\"\\nüìä Step 4: Evaluating Multi-Output CNN...\")\n",
        "evaluator = evaluate_multi_output_cnn_pipeline(\n",
        "    model_results=trainer.training_history,\n",
        "    y_gender_test=y_gender_test,\n",
        "    y_digit_test=y_digit_test,\n",
        "    output_dir=OUTPUT_DIR\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Multi-Output CNN Pipeline Completed!\")\n",
        "print(\"üìä Results Summary:\")\n",
        "print(f\"   - Best overall accuracy: {trainer.best_accuracy:.4f}\")\n",
        "print(f\"   - Model architecture: Multi-Output CNN with shared conv layers\")\n",
        "print(f\"   - Features: MFCC (13 coefficients, 100 time frames)\")\n",
        "print(f\"   - Train/Test split: 70/30\")\n",
        "print(f\"   - Loss function: Categorical crossentropy\")\n",
        "print(f\"   - Evaluation metrics: Accuracy, Precision, Recall, F1-score\")\n",
        "\n",
        "print(\"\\nüéâ Multi-Output CNN pipeline execution completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
